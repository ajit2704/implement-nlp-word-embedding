{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module3_Demo3_Build_CBOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO9VtqC01oFaaKiCd1EgMV+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axel-sirota/implement-nlp-word-embedding/blob/main/module3/Module3_Demo3_Build_CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxVnLgTHNCBR",
        "outputId": "ac1e82f6-2150-4285-81f7-9d3518ec1346"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.25.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchdata) (4.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFQM_HAJgHEz",
        "outputId": "590c37d2-4915-4294-862a-c247f22792f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import AG_NEWS\n",
        "import warnings\n",
        "import os\n",
        "from textblob import TextBlob, Word\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile get_data.sh\n",
        "if [ ! -f yelp.csv ]; then\n",
        "  wget https://raw.githubusercontent.com/axel-sirota/implement-nlp-word-embedding/main/module3/data/yelp.csv\n",
        "fi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hP5znc6NBCg",
        "outputId": "2d747d1b-99a7-4ac5-cc26-bda8ce9a0eac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing get_data.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_data.sh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bh1RqQUPWeo",
        "outputId": "7fd3fdc3-d3d3-4cd3-f401-fe8e958d3d64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-25 17:27:18--  https://raw.githubusercontent.com/axel-sirota/implement-nlp-word-embedding/main/module3/data/yelp.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8091185 (7.7M) [text/plain]\n",
            "Saving to: ‘yelp.csv’\n",
            "\n",
            "yelp.csv            100%[===================>]   7.72M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-05-25 17:27:19 (136 MB/s) - ‘yelp.csv’ saved [8091185/8091185]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = './yelp.csv'\n",
        "yelp = pd.read_csv(path)\n",
        "text_df = yelp.text"
      ],
      "metadata": {
        "id": "7jcOGQHDPYP6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 300\n",
        "CORPUS_SIZE = 10000\n",
        "train_size = 100000"
      ],
      "metadata": {
        "id": "s_1umLOsgk5R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(data_iter, tokenizer):\n",
        "    \"\"\"Builds vocabulary from iterator\"\"\"\n",
        "    vocab = build_vocab_from_iterator(\n",
        "        yield_tokens(data_iter, tokenizer),\n",
        "        specials=[\"<unk>\"],\n",
        "        min_freq=10,\n",
        "    )\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])\n",
        "    return vocab\n",
        "\n",
        "def yield_tokens(data_iter, tokenizer):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n"
      ],
      "metadata": {
        "id": "LNIYzlnzhZIC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_sampled = text_df.sample(CORPUS_SIZE).values"
      ],
      "metadata": {
        "id": "ucls-7mkNQHa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = lambda x: TextBlob(x).words\n",
        "vocab = build_vocab(text_sampled, tokenizer)\n",
        "print(f'Vocab size is {len(vocab)}')"
      ],
      "metadata": {
        "id": "0d4exCm_hyPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7087363-74a6-48b4-8c13-2da6f75ff1e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size is 6854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdMAq5FMjVDt",
        "outputId": "febf1661-e176-4c3e-96d2-f1e778c4ccbc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Vocab()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(tokenizer(\"This is a fantastic ice cream\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xau74OLTjz5z",
        "outputId": "1ffdfb3a-6f2d-4f57-de8e-10c9d7d29b52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[78, 8, 4, 387, 385, 309]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(text_sampled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "HK_AkCK5mSwT",
        "outputId": "be0b6237-8249-477e-8c24-55f159a38422"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'One hour. That is how long we waited after ordering before we decided we would rather eat anywhere that wasn\\'t here. A crushing, impressively underwhelming experience in lack of service.\\n\\nWe arrived, found we had free valet parking? With a teensy parking lot, this works, thank you. A good selection of indoor and outdoor seating? Also a plus. Setting expectations and/or taking care of waiting customers? FAIL.\\n\\nOn a beautiful AZ autumn morning we came here (tho we entered Rockerij). We asked to be re-seated outside because inside of Rockerij is dark as a tomb and had loud, conversation intruding, music. We were reseated by the fireplace, and a waiter came over shortly to take our order. Bam. So far so good...or so we thought. 30 Mins after placing our order, I ask another waiter to check on the status of our food and he cleverly asks about what we ordered (exactly)...so we think it is being taken care of. 40 MINS after placing our order, I have still only had my coffee refilled once...and had to flag down another waiter to inquire about the status of our food again, because our actual waiter is nowhere to be found and the previous \"drive-by\" waiter never returned. A few mins beyond that, this guy actually comes back and indicates that our order is nearly ready and should only be a few minutes longer. Shortly thereafter OUR waiter stops by with comments of: \\n\\n\"I don\\'t know why it\\'s taking so long...\"\\nand\\n\"I put the ticket in right after I took your order...\"\\n\\nSo...as a waiter...maybe it might be part of your job to check on the status of an order say...15mins after bringing it by the kitchen? Perchance? What do you think?\\n\\nFIFTEEN (15 == few?) minutes later, we still had no food and I\\'d had quite enough. Out the door we went.\\n\\nOn a comical note: As we were outside (another 5 minute wait because the valet had our car either parked in Egypt somewhere or tandem?) our waiter came out to find us to let us know that our food was ready if we\\'d like to come back inside?\\n\\nOh R E A L L Y? The Clue-Delivery Train will be visiting you shortly. Facial cues you may want to look for in the future are:\\n1) the furrowed eyebrows\\n2) fuck-you facial expression\\nand\\n3) curling fists\\n\\nIt seems that we are not alone in this. Courtney W.\\'s review (10/14/12) is representative of what we experienced.\\n\\nI am dumbfounded how they have any good reviews. There must be a serious drought of sit down restaurants in this part of town, because this crap would never fly where I live. I cannot tell you how much I am looking forward to NEVER COMING HERE AGAIN.\\n\\nP.S. They own 3 restaurants apparently: Richardson\\'s, Rokerij, and Dick\\'s Hideaway...all right in the same area (Rokerij and Richardson\\'s being attached). \\n\\nP.P.S. They all serve the same menu. It is NOT amazing. I have previously been to Dick\\'s. Yes, it is good. No my socks did not come flying off.\\n\\nP.P.P.S. ProTip: Drive down to Central Phoenix and go to Durant\\'s, Portland\\'s, Switch, or Fez. All of these places have exemplary service and food to match.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "word_to_ix = {}\n",
        "for sentence in text_sampled:\n",
        "  for word in tokenizer(sentence):\n",
        "    word_to_ix[word] = vocab([word])[0]"
      ],
      "metadata": {
        "id": "6y7KGL1fiMDc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ix_to_word = {ix:word for word, ix in word_to_ix.items()}"
      ],
      "metadata": {
        "id": "NPwMGoeyjEy6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for sentence in text_sampled:\n",
        "  tokenized_sentence = tokenizer(sentence)\n",
        "  for i in range(2, len(tokenized_sentence) - 2):\n",
        "    context = [tokenized_sentence[i - 2], tokenized_sentence[i - 1],\n",
        "               tokenized_sentence[i + 1], tokenized_sentence[i + 2]]\n",
        "    target = tokenized_sentence[i]\n",
        "    data.append((context, target))"
      ],
      "metadata": {
        "id": "BCcPLFM0kqc_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Lenght of input (sampled) text set is {len(data)}, reducing it to {train_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM0Znu5VP5D2",
        "outputId": "5a7ba8de-b435-488a-8c50-8550fbbf71b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenght of input (sampled) text set is 1294617, reducing it to 100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[:train_size]"
      ],
      "metadata": {
        "id": "4wkpTaHSQIcw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long).to(device)"
      ],
      "metadata": {
        "id": "Mb0CbAZ4qihA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        "\n",
        "        #out: 1 x emdedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "        \n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "metadata": {
        "id": "Ils21-oJqizc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CBOW(vocab_size, EMBEDDING_DIM).to(device)"
      ],
      "metadata": {
        "id": "r9z1qVbYre9O"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_pred, y):\n",
        "  return nn.functional.nll_loss(y_pred, y)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters())"
      ],
      "metadata": {
        "id": "iBTpSE2PrhYL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_pd = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "Y2lNhbSSv73x"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pNKBxIZuwPHa",
        "outputId": "281b2406-9eb5-4f35-a976-c267abc9f769"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                0     1\n",
              "0            [One, hour, is, how]  That\n",
              "1         [hour, That, how, long]    is\n",
              "2            [That, is, long, we]   how\n",
              "3           [is, how, we, waited]  long\n",
              "4      [how, long, waited, after]    we\n",
              "...                           ...   ...\n",
              "99995       [ago, and, was, some]    it\n",
              "99996         [and, it, some, of]   was\n",
              "99997          [it, was, of, the]  some\n",
              "99998      [was, some, the, best]    of\n",
              "99999       [some, of, best, BBQ]   the\n",
              "\n",
              "[100000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16dc5a9e-bf19-4bba-a0d4-9fee107236f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[One, hour, is, how]</td>\n",
              "      <td>That</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[hour, That, how, long]</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[That, is, long, we]</td>\n",
              "      <td>how</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[is, how, we, waited]</td>\n",
              "      <td>long</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[how, long, waited, after]</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>[ago, and, was, some]</td>\n",
              "      <td>it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>[and, it, some, of]</td>\n",
              "      <td>was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>[it, was, of, the]</td>\n",
              "      <td>some</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>[was, some, the, best]</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>[some, of, best, BBQ]</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16dc5a9e-bf19-4bba-a0d4-9fee107236f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16dc5a9e-bf19-4bba-a0d4-9fee107236f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16dc5a9e-bf19-4bba-a0d4-9fee107236f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  ix = 0\n",
        "  for context, target in data:\n",
        "      context_vector = make_context_vector(context, word_to_ix)\n",
        "      log_probs = model(context_vector)\n",
        "      total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]).to(device))\n",
        "  print(f\"-\"*59)\n",
        "  print(f\"Epoch: {epoch} Loss: {total_loss}\")\n",
        "  total_loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj2XomjrtOlH",
        "outputId": "d5c06ba7-3158-45a9-c819-5feeaaf427b6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------\n",
            "Epoch: 0 Loss: 951782.1875\n",
            "-----------------------------------------------------------\n",
            "Epoch: 1 Loss: 930395.25\n",
            "-----------------------------------------------------------\n",
            "Epoch: 2 Loss: 909755.4375\n",
            "-----------------------------------------------------------\n",
            "Epoch: 3 Loss: 889897.75\n",
            "-----------------------------------------------------------\n",
            "Epoch: 4 Loss: 870840.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = ['People','create','to', 'direct']\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "a = model(context_vector)\n",
        "\n",
        "#Print result\n",
        "print(f'Context: {context}\\n')\n",
        "print(f'Prediction: {ix_to_word[torch.argmax(a[0]).item()]}')"
      ],
      "metadata": {
        "id": "baEKAnFTt6ZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "743fdccb-9453-4f47-eb5e-6250402ff770"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: ['People', 'create', 'to', 'direct']\n",
            "\n",
            "Prediction: forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding from first model layer\n",
        "embeddings = list(model.parameters())[0]\n",
        "embeddings = embeddings.cpu().detach().numpy()\n",
        "\n",
        "# normalization\n",
        "norms = (embeddings ** 2).sum(axis=1) ** (1 / 2)\n",
        "norms = np.reshape(norms, (len(norms), 1))\n",
        "embeddings_norm = embeddings / norms\n",
        "embeddings_norm.shape"
      ],
      "metadata": {
        "id": "V3N0NXnSuzVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebabefe3-577e-418b-8261-9d2d2c180fcf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6854, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_similar(word, topN=10):\n",
        "    word_vec = model.to(\"cpu\").get_word_emdedding(word).detach().numpy()[0]\n",
        "    word_vec = np.reshape(word_vec, (len(word_vec), 1))\n",
        "    dists = np.matmul(embeddings_norm, word_vec).flatten()\n",
        "    topN_ids = np.argsort(-dists)[1 : topN + 1]\n",
        "    topN_dict = {}\n",
        "    for sim_word_id in topN_ids:\n",
        "        sim_word = ix_to_word[sim_word_id]\n",
        "        topN_dict[sim_word] = dists[sim_word_id]\n",
        "    return topN_dict\n",
        "\n",
        "model.eval()\n",
        "for word, sim in get_top_similar(\"excellent\").items():\n",
        "    print(\"{}: {:.3f}\".format(word, sim))\n",
        "\n"
      ],
      "metadata": {
        "id": "b51uwCryuZnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aaafa5f-6358-44ed-a87d-a518b3cd673b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "onions: 4.011\n",
            "code: 3.965\n",
            "Crust: 3.657\n",
            "closest: 3.307\n",
            "drag: 3.303\n",
            "Salon: 3.157\n",
            "wings: 3.147\n",
            "Rama: 3.135\n",
            "advice: 3.056\n",
            "Culinary: 3.018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZouAmamvTE8W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}